{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "wandb: WARNING Keras version 2.3.1 is not fully supported. Required keras >= 2.4.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten\n",
    "from keras.applications.resnet50 import ResNet50, decode_predictions, preprocess_input\n",
    "from keras.applications.xception import Xception\n",
    "import DatasetParser\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299\n",
      "Entrenamiento: 3348\n",
      "Test: 1440\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train_raw), (x_test, y_test_raw), class_names = DatasetParser.load_data(\"Xception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode ouput\n",
    "y_train = keras.utils.to_categorical(y_train_raw)\n",
    "y_test = keras.utils.to_categorical(y_test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xception_model = keras.applications.Xception(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=(299, 299, 3),\n",
    "    include_top=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: [('n03775546', 'mixing_bowl', 0.90169585), ('n02112350', 'keeshond', 0.09713012), ('n03942813', 'ping-pong_ball', 0.0011666301)]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "img = image.load_img('elephant.jpg', target_size=(299, 299))\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = preprocess_input(x)\n",
    "preds = Xception_model.predict(x)\n",
    "print('Predicted:', decode_predictions(preds, top=3)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We should preprocess the images the same way resnet images were preprocessed\n",
    "x_train_preprocessed = preprocess_input(x_train)\n",
    "x_test_preprocessed = preprocess_input(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 299, 299, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 74, 74, 128)  512         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 37, 37, 256)  32768       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 37, 37, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 19, 19, 728)  186368      add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 19, 19, 728)  2912        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 1024) 745472      add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 10, 10, 1024) 4096        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 20,806,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build a new model that is ResNet50 minus the very last layer\n",
    "last_layer = Xception_model.get_layer(\"avg_pool\")\n",
    "\n",
    "Xception_layers = keras.Model(inputs=Xception_model.inputs, outputs=last_layer.output)\n",
    "Xception_layers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use our resnet to \"predict\" but because we have removed the top layer, \n",
    "# this outputs the activations of the second to last layer on our dataset\n",
    "\n",
    "x_train_features = Xception_layers.predict(x_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_features = Xception_layers.predict(x_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 2048)              20861480  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 36)                73764     \n",
      "=================================================================\n",
      "Total params: 20,935,244\n",
      "Trainable params: 73,764\n",
      "Non-trainable params: 20,861,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can directly stich the models together\n",
    "\n",
    "Fine_Tuning_model=Sequential()\n",
    "Fine_Tuning_model.add(Xception_layers)\n",
    "Fine_Tuning_model.add(Dense(36, activation=\"softmax\"))\n",
    "\n",
    "Fine_Tuning_model.layers[0].trainable=False\n",
    "\n",
    "Fine_Tuning_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "Fine_Tuning_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: scueroinc (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.10.25 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.8<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">splendid-lake-10</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/scueroinc/test\" target=\"_blank\">https://wandb.ai/scueroinc/test</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/scueroinc/test/runs/262rxwhm\" target=\"_blank\">https://wandb.ai/scueroinc/test/runs/262rxwhm</a><br/>\n",
       "                Run data is saved locally in <code>wandb\\run-20210407_141226-262rxwhm</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3348 samples, validate on 1440 samples\n",
      "Epoch 1/15\n",
      "3348/3348 [==============================] - 90s 27ms/step - loss: 2.5381 - accuracy: 0.4143 - val_loss: 24.3881 - val_accuracy: 0.0236\n",
      "Epoch 2/15\n",
      "3348/3348 [==============================] - 88s 26ms/step - loss: 1.3831 - accuracy: 0.7240 - val_loss: 31.5003 - val_accuracy: 0.0167\n",
      "Epoch 3/15\n",
      "3348/3348 [==============================] - 89s 27ms/step - loss: 0.9887 - accuracy: 0.7957 - val_loss: 40.8784 - val_accuracy: 0.0167\n",
      "Epoch 4/15\n",
      "3348/3348 [==============================] - 89s 27ms/step - loss: 0.7973 - accuracy: 0.8309 - val_loss: 39.7179 - val_accuracy: 0.0181\n",
      "Epoch 5/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.6754 - accuracy: 0.8542 - val_loss: 47.2827 - val_accuracy: 0.0208\n",
      "Epoch 6/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.5816 - accuracy: 0.8778 - val_loss: 49.9274 - val_accuracy: 0.0194\n",
      "Epoch 7/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.5205 - accuracy: 0.8970 - val_loss: 55.0349 - val_accuracy: 0.0181\n",
      "Epoch 8/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.4678 - accuracy: 0.9002 - val_loss: 53.5660 - val_accuracy: 0.0201\n",
      "Epoch 9/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.4157 - accuracy: 0.9149 - val_loss: 54.8053 - val_accuracy: 0.0188\n",
      "Epoch 10/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.3769 - accuracy: 0.9331 - val_loss: 58.8578 - val_accuracy: 0.0153\n",
      "Epoch 11/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.3372 - accuracy: 0.9376 - val_loss: 69.3742 - val_accuracy: 0.0188\n",
      "Epoch 12/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.3136 - accuracy: 0.9441 - val_loss: 68.9240 - val_accuracy: 0.0194\n",
      "Epoch 13/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.2923 - accuracy: 0.9489 - val_loss: 70.0489 - val_accuracy: 0.0201\n",
      "Epoch 14/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.2726 - accuracy: 0.9543 - val_loss: 66.4667 - val_accuracy: 0.0181\n",
      "Epoch 15/15\n",
      "3348/3348 [==============================] - 89s 26ms/step - loss: 0.2599 - accuracy: 0.9534 - val_loss: 71.9635 - val_accuracy: 0.0181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22ad1c1e5c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.init(project='test', entity='scueroinc')\n",
    "Fine_Tuning_model.fit(x_train_preprocessed, y_train, epochs=15, validation_data=(x_test_preprocessed, y_test), callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3348 samples, validate on 1440 samples\n",
      "Epoch 1/30\n",
      "3348/3348 [==============================] - 100s 30ms/step - loss: 0.5023 - accuracy: 0.8536 - val_loss: 1.2582 - val_accuracy: 0.7500\n",
      "Epoch 2/30\n",
      "3348/3348 [==============================] - 96s 29ms/step - loss: 0.1028 - accuracy: 0.9689 - val_loss: 1.0386 - val_accuracy: 0.7688\n",
      "Epoch 3/30\n",
      "3348/3348 [==============================] - 96s 29ms/step - loss: 0.0655 - accuracy: 0.9824 - val_loss: 0.7939 - val_accuracy: 0.8146\n",
      "Epoch 4/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0564 - accuracy: 0.9815 - val_loss: 1.2610 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0307 - accuracy: 0.9901 - val_loss: 0.8562 - val_accuracy: 0.8111\n",
      "Epoch 6/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0168 - accuracy: 0.9955 - val_loss: 0.8069 - val_accuracy: 0.8208\n",
      "Epoch 7/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0347 - accuracy: 0.9892 - val_loss: 0.9494 - val_accuracy: 0.8028\n",
      "Epoch 8/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 1.0106 - val_accuracy: 0.7882\n",
      "Epoch 9/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.8037 - val_accuracy: 0.8222\n",
      "Epoch 10/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0509 - accuracy: 0.9866 - val_loss: 1.3923 - val_accuracy: 0.7563\n",
      "Epoch 11/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0406 - accuracy: 0.9898 - val_loss: 1.0402 - val_accuracy: 0.8097\n",
      "Epoch 12/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0264 - accuracy: 0.9916 - val_loss: 1.0170 - val_accuracy: 0.8194\n",
      "Epoch 13/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0293 - accuracy: 0.9928 - val_loss: 1.3763 - val_accuracy: 0.7333\n",
      "Epoch 14/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0644 - accuracy: 0.9833 - val_loss: 1.1131 - val_accuracy: 0.8146\n",
      "Epoch 15/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0431 - accuracy: 0.9854 - val_loss: 1.8733 - val_accuracy: 0.7167\n",
      "Epoch 16/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0209 - accuracy: 0.9937 - val_loss: 1.1595 - val_accuracy: 0.8125\n",
      "Epoch 17/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0279 - accuracy: 0.9913 - val_loss: 1.1707 - val_accuracy: 0.8035\n",
      "Epoch 18/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0141 - accuracy: 0.9961 - val_loss: 0.8861 - val_accuracy: 0.8347\n",
      "Epoch 19/30\n",
      "3348/3348 [==============================] - 96s 29ms/step - loss: 0.0215 - accuracy: 0.9949 - val_loss: 0.9302 - val_accuracy: 0.8229\n",
      "Epoch 20/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.8395 - val_accuracy: 0.8354\n",
      "Epoch 21/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0069 - accuracy: 0.9973 - val_loss: 0.8892 - val_accuracy: 0.8250\n",
      "Epoch 22/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0034 - accuracy: 0.9997 - val_loss: 0.8057 - val_accuracy: 0.8500\n",
      "Epoch 23/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 7.9839e-04 - accuracy: 1.0000 - val_loss: 0.7713 - val_accuracy: 0.8542\n",
      "Epoch 24/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 9.5996e-04 - accuracy: 1.0000 - val_loss: 0.7191 - val_accuracy: 0.8562\n",
      "Epoch 25/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 7.2127e-04 - accuracy: 1.0000 - val_loss: 0.7287 - val_accuracy: 0.8639\n",
      "Epoch 26/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 5.1349e-04 - accuracy: 1.0000 - val_loss: 0.7473 - val_accuracy: 0.8646\n",
      "Epoch 27/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 8.3728e-04 - accuracy: 0.9997 - val_loss: 0.7913 - val_accuracy: 0.8562\n",
      "Epoch 28/30\n",
      "3348/3348 [==============================] - 98s 29ms/step - loss: 0.0083 - accuracy: 0.9979 - val_loss: 0.7787 - val_accuracy: 0.8417\n",
      "Epoch 29/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0686 - accuracy: 0.9839 - val_loss: 1.5581 - val_accuracy: 0.7410\n",
      "Epoch 30/30\n",
      "3348/3348 [==============================] - 97s 29ms/step - loss: 0.0893 - accuracy: 0.9686 - val_loss: 2.6549 - val_accuracy: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22c0b4cbac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can allow some of the resnet layers to change as we train.  \n",
    "# Typically you would want to lower the learning rate in conjunction with this.\n",
    "\n",
    "Fine_Tuning_model.layers[0].trainable = True\n",
    "\n",
    "# We let the last 3 blocks train\n",
    "for layer in Fine_Tuning_model.layers[0].layers[:-11]:\n",
    "    layer.trainable = False\n",
    "for layer in Fine_Tuning_model.layers[0].layers[-11:]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "Fine_Tuning_model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "Fine_Tuning_model.fit(x_train_preprocessed, y_train, epochs=30, validation_data=(x_test_preprocessed, y_test), callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
